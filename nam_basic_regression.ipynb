{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import requests\n",
    "import shutil\n",
    "from pprint import pprint\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the NAM data (split into training and testing)\n",
    "# NOTE: must have run the \"nam_data_preparation.ipynb\" notebook beforehand\n",
    "\n",
    "# Read the training and testing data from disk\n",
    "cleaned_data = \"cleaned_data/\"\n",
    "training_data_filename = \"nam_training_\"\n",
    "testing_data_filename = \"nam_testing_\"\n",
    "extension = \".pkl.gz\"\n",
    "nam_training_df = None\n",
    "for i in range(32):\n",
    "    training_part = pd.read_pickle(cleaned_data + training_data_filename + str(i) + extension, compression='gzip')\n",
    "    nam_training_df = training_part if nam_training_df is None else nam_training_df.append(training_part)\n",
    "    del training_part\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                data_objects\n",
      "timestamps                                                                  \n",
      "2015-01-01 01:00:00-06:00  [[[0.0, 290.43628, 0.0, 73.0, 101516.0, 295.77...\n",
      "2015-01-01 02:00:00-06:00  [[[0.0, 290.8083, 0.0, 74.0, 101502.0, 295.740...\n",
      "2015-01-01 03:00:00-06:00  [[[0.0, 290.99026, 0.0, 75.0, 101467.0, 295.66...\n",
      "2015-01-01 04:00:00-06:00  [[[0.0, 290.83884, 0.0, 75.0, 101436.0, 295.67...\n",
      "2015-01-01 05:00:00-06:00  [[[0.0, 290.83582, 0.0, 75.0, 101412.0, 295.64...\n",
      "                                                                data_objects\n",
      "timestamps                                                                  \n",
      "2018-12-31 17:00:00-06:00  [[[0.0, 283.83853, 268.59998, 58.5307, 101409....\n",
      "2018-12-31 18:00:00-06:00  [[[0.0, 284.02292, 77.4, 58.640553, 101367.984...\n",
      "2018-12-31 19:00:00-06:00  [[[0.0, 284.31033, 51.6, 59.009323, 101398.63,...\n",
      "2018-12-31 20:00:00-06:00  [[[0.0, 284.59775, 25.8, 59.378094, 101429.28,...\n",
      "2018-12-31 21:00:00-06:00  [[[0.0, 284.88516, 0.0, 59.746864, 101459.94, ...\n"
     ]
    }
   ],
   "source": [
    "# Print the training dataset out\n",
    "pprint(nam_training_df[:5])\n",
    "pprint(nam_training_df[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the ERCOT data (reduced hourly and split into train/test in a 24:1 ratio)\n",
    "training_data_filename = \"ercot_wind_power.pkl\"\n",
    "training_expected_output_filename = \"ercot_for_nam_training\"\n",
    "testing_expected_output_filename = \"ercot_for_nam_testing\"\n",
    "\n",
    "# If we haven't already done this split, do it now and save the contents to disk\n",
    "if not path.exists(cleaned_data + training_expected_output_filename + extension) or not path.exists(cleaned_data + testing_expected_output_filename + extension):\n",
    "    print(\"cleaning ERCOT data for NAM purposes\")\n",
    "\n",
    "#     # Download the ERCOT dataset if needed\n",
    "#     if not path.exists(training_data_filename):\n",
    "#         TODO figure out how to correctly download this pickle file, because this code doesn't work\n",
    "#         r = requests.get(\"http://storage.googleapis.com/gridmatic/roscoe/\" + training_data_filename, stream=True)\n",
    "#         pickle(r.raw, training_data_filename)\n",
    "#         with open(training_data_filename, 'wb') as fin:\n",
    "#             shutil.copyfileobj(r.raw, fin)\n",
    "#             fin.close()\n",
    "\n",
    "    # Get generically cleaned ERCOT data, not specifically set up for use with NAM\n",
    "    ercot_wind_power = pd.read_pickle(\"ercot_wind_power.pkl\")\n",
    " \n",
    "    # ERCOT data is every 15 minutes, while the NAM data is hourly\n",
    "    # We therefore only use the ERCOT data on the hour, when working with NAM\n",
    "    hourly_ercot = ercot_wind_power[::4]\n",
    "\n",
    "    # Small change: NAM ends at 21:00 on Dec 31 2018, while ERCOT ends at 23:00\n",
    "    # So cut out the last two entries of hourly_ercot\n",
    "    hourly_ercot = hourly_ercot.iloc[:-2]\n",
    "\n",
    "    # Split the ERCOT data to line up with the NAM data\n",
    "    hourly_ercot['numerical_index'] = range(0, len(hourly_ercot))\n",
    "    ercot_training_df = hourly_ercot[hourly_ercot['numerical_index'] % 25 != 0]\n",
    "    ercot_testing_df = hourly_ercot[hourly_ercot['numerical_index'] % 25 == 0]\n",
    "    del hourly_ercot\n",
    "    gc.collect()\n",
    "    ercot_training_df = ercot_training_df.drop('numerical_index', 1)\n",
    "    ercot_testing_df = ercot_testing_df.drop('numerical_index', 1)\n",
    "    \n",
    "    # Save the ERCOT data to file\n",
    "    ercot_training_df.to_pickle(cleaned_data + training_expected_output_filename + extension, compression='gzip')\n",
    "    ercot_testing_df.to_pickle(cleaned_data + testing_expected_output_filename + extension, compression='gzip')\n",
    "    del ercot_training_df\n",
    "    del ercot_testing_df\n",
    "    gc.collect()\n",
    "\n",
    "# Get the NAM-specific ERCOT data from disk\n",
    "ercot_training_df = pd.read_pickle(cleaned_data + training_expected_output_filename + extension, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resource_code              ANACACHO_ANA  ASTRA_UNIT1  BCATWIND_WIND_1\n",
      "timestamp                                                            \n",
      "2015-01-01 01:00:00-06:00           0.0          NaN              0.0\n",
      "2015-01-01 02:00:00-06:00           0.0          NaN              0.0\n",
      "2015-01-01 03:00:00-06:00           0.0          NaN              0.0\n",
      "2015-01-01 04:00:00-06:00           0.0          NaN              0.0\n",
      "2015-01-01 05:00:00-06:00           0.0          NaN              0.0\n",
      "resource_code              ANACACHO_ANA  ASTRA_UNIT1  BCATWIND_WIND_1\n",
      "timestamp                                                            \n",
      "2018-12-31 17:00:00-06:00      0.000000     33.30522         11.35381\n",
      "2018-12-31 18:00:00-06:00      0.000000     36.93887         12.76649\n",
      "2018-12-31 19:00:00-06:00      0.000000     38.98851         23.02475\n",
      "2018-12-31 20:00:00-06:00      0.582387     39.37746         34.87904\n",
      "2018-12-31 21:00:00-06:00      7.234724     39.16596         33.18754\n"
     ]
    }
   ],
   "source": [
    "# Print the training dataset out\n",
    "pprint(ercot_training_df.iloc[:5,:3])\n",
    "pprint(ercot_training_df.iloc[-5:,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the NAM locations\n",
    "# Locations corresponding to each of the NAM forecasts (140x140x2)\n",
    "# Latitude and longitude were originally in the opposite order from the coordinate data for the wind farms\n",
    "# That's why we use this secondary file\n",
    "nam_locations = np.load(\"nam_locations_flipped.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[[-107.76918787,   23.53865642],\n",
      "        [-107.65016388,   23.54891584],\n",
      "        [-107.53112034,   23.5590795 ],\n",
      "        ...,\n",
      "        [ -91.35751774,   24.04493008],\n",
      "        [ -91.23753108,   24.04193683],\n",
      "        [ -91.11755031,   24.03884662]],\n",
      "\n",
      "       [[-107.78044054,   23.64776964],\n",
      "        [-107.6613129 ,   23.65803855],\n",
      "        [-107.54216564,   23.66821161],\n",
      "        ...,\n",
      "        [ -91.35429032,   24.15450932],\n",
      "        [ -91.23419745,   24.15151333],\n",
      "        [ -91.11411049,   24.14842029]],\n",
      "\n",
      "       [[-107.79171301,   23.75688688],\n",
      "        [-107.67248153,   23.76716526],\n",
      "        [-107.55323038,   23.7773477 ],\n",
      "        ...,\n",
      "        [ -91.35105718,   24.26409157],\n",
      "        [ -91.23085791,   24.26109285],\n",
      "        [ -91.11066457,   24.25799698]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-109.51991989,   38.35614736],\n",
      "        [-109.38480872,   38.36748391],\n",
      "        [-109.24966885,   38.3787143 ],\n",
      "        ...,\n",
      "        [ -90.8547987 ,   38.91516188],\n",
      "        [ -90.71827237,   38.9118593 ],\n",
      "        [ -90.58175473,   38.90844969]],\n",
      "\n",
      "       [[-109.53445883,   38.4620606 ],\n",
      "        [-109.39921442,   38.47340313],\n",
      "        [-109.26394123,   38.48463945],\n",
      "        ...,\n",
      "        [ -90.85061872,   39.02136704],\n",
      "        [ -90.7139549 ,   39.01806276],\n",
      "        [ -90.5772998 ,   39.01465139]],\n",
      "\n",
      "       [[-109.5490268 ,   38.56792278],\n",
      "        [-109.41364889,   38.57927128],\n",
      "        [-109.27824212,   38.5905135 ],\n",
      "        ...,\n",
      "        [ -90.8464303 ,   39.12751968],\n",
      "        [ -90.70962872,   39.1242137 ],\n",
      "        [ -90.57283587,   39.12080058]]])\n"
     ]
    }
   ],
   "source": [
    "pprint(nam_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ANACACHO_ANA': [-100.15802, 29.215214],\n",
      " 'ASTRA_UNIT1': [-102.071477, 34.786654],\n",
      " 'BCATWIND_WIND_1': [-98.570491, 33.509188],\n",
      " 'BLSUMMIT_BLSMT1_5': [-99.367467, 34.293473],\n",
      " 'BLSUMMIT_BLSMT1_6': [-99.367467, 34.293473],\n",
      " 'BORDAS2_JAVEL2_A': [-98.931877, 27.358092],\n",
      " 'BORDAS2_JAVEL2_B': [-98.931877, 27.358092],\n",
      " 'BORDAS2_JAVEL2_C': [-98.931877, 27.358092],\n",
      " 'BORDAS_JAVEL18': [-98.931877, 27.358092],\n",
      " 'BORDAS_JAVEL20': [-98.931877, 27.358092],\n",
      " 'BRAZ_WND_WND1': [-101.146911, 32.949884],\n",
      " 'BRAZ_WND_WND2': [-101.146911, 32.949884],\n",
      " 'BRISCOE_WIND': [-101.374278, 34.371453],\n",
      " 'BRTSW_BCW1': [-98.363595, 33.073455],\n",
      " 'BUCKTHRN_UNIT1': [-98.353682, 32.376956],\n",
      " 'BUCKTHRN_UNIT2': [-98.353682, 32.376956],\n",
      " 'BUFF_GAP_UNIT1': [-100.115386, 32.298543],\n",
      " 'BUFF_GAP_UNIT2_1': [-100.115386, 32.298543],\n",
      " 'BUFF_GAP_UNIT2_2': [-100.115386, 32.298543],\n",
      " 'BUFF_GAP_UNIT3': [-100.115386, 32.298543],\n",
      " 'BULLCRK_WND1': [-101.605095, 32.906769],\n",
      " 'BULLCRK_WND2': [-101.605095, 32.906769],\n",
      " 'CALLAHAN_WND1': [-99.995602, 32.296385],\n",
      " 'CAPRIDG4_CR4': [-100.928076, 31.926188],\n",
      " 'CAPRIDGE_CR1': [-100.928076, 31.926188],\n",
      " 'CAPRIDGE_CR2': [-100.928076, 31.926188],\n",
      " 'CAPRIDGE_CR3': [-100.928076, 31.926188],\n",
      " 'CEDROHIL_CHW1': [-98.843784, 27.608743],\n",
      " 'CEDROHIL_CHW2': [-98.843784, 27.608743],\n",
      " 'CHAMPION_UNIT1': [-95.104872, 29.876916],\n",
      " 'COTPLNS_COTTONPL': [-101.184903, 33.979043],\n",
      " 'COTPLNS_OLDSETLR': [-97.424589, 27.950722],\n",
      " 'CSEC_CSECG1': [-100.83267, 32.753102],\n",
      " 'CSEC_CSECG2': [-100.83267, 32.753102],\n",
      " 'DERMOTT_UNIT1': [-100.975986, 32.864857],\n",
      " 'DERMOTT_UNIT2': [-100.975986, 32.864857],\n",
      " 'DIGBY_UNIT1': [-95.085844, 29.723605],\n",
      " 'DIGBY_UNIT2': [-95.085844, 29.723605],\n",
      " 'ELB_ELBCREEK': [-101.398767, 32.140883],\n",
      " 'ENAS_ENA1': [-100.735316, 32.73004],\n",
      " 'EXGNSND_WIND_1': [-98.909318, 27.191033],\n",
      " 'EXGNWTL_WIND_1': [-98.909318, 27.191033],\n",
      " 'FERMI_WIND1': [-100.711921, 29.76559],\n",
      " 'FERMI_WIND2': [-100.711921, 29.76559],\n",
      " 'FLTCK_SSI': [-98.46429, 32.33178],\n",
      " 'FLUVANNA_UNIT1': [-101.157666, 32.889822],\n",
      " 'FLUVANNA_UNIT2': [-101.157666, 32.889822],\n",
      " 'GOAT_GOATWIN2': [-100.861431, 31.909922],\n",
      " 'GOAT_GOATWIND': [-100.861431, 31.909922],\n",
      " 'GPASTURE_WIND_I': [-99.368737, 33.673808],\n",
      " 'GRANDVW1_COLA': [-101.36045, 35.25418],\n",
      " 'GRANDVW1_COLB': [-101.36045, 35.25418],\n",
      " 'GRANDVW1_GV1A': [-101.36045, 35.25418],\n",
      " 'GRANDVW1_GV1B': [-101.36045, 35.25418],\n",
      " 'GUNMTN_G1': [-101.410181, 32.196647],\n",
      " 'GWEC_GWEC_G1': [-98.56649, 31.43098],\n",
      " 'HHOLLOW2_WIND1': [-100.040198, 32.226344],\n",
      " 'HHOLLOW3_WND_1': [-100.040198, 32.226344],\n",
      " 'HHOLLOW4_WND1': [-100.040198, 32.226344],\n",
      " 'HORSECRK_UNIT1': [-99.552687, 33.289897],\n",
      " 'HORSECRK_UNIT2': [-99.552687, 33.289897],\n",
      " 'HRFDWIND_JRDWIND1': [-102.30457, 34.77335],\n",
      " 'HRFDWIND_JRDWIND2': [-102.30457, 34.77335],\n",
      " 'HRFDWIND_WIND_G': [-102.30457, 34.77335],\n",
      " 'HRFDWIND_WIND_V': [-102.30457, 34.77335],\n",
      " 'HWF_HWFG1': [-99.278334, 32.824168],\n",
      " 'H_HOLLOW_WND1': [-100.040198, 32.226344],\n",
      " 'INDL_INADALE1': [-100.596358, 32.497305],\n",
      " 'INDL_INADALE2': [-100.596358, 32.497305],\n",
      " 'INDNENR_INDNENR': [-102.092793, 30.915068],\n",
      " 'INDNENR_INDNENR_2': [-102.092793, 30.915068],\n",
      " 'KEECHI_U1': [-98.217426, 33.113825],\n",
      " 'KEO_KEO_SM1': [-102.365451, 30.822282],\n",
      " 'KEO_SHRBINO2': [-102.365451, 30.822282],\n",
      " 'KING_NE_KINGNE': [-102.24149, 31.208996],\n",
      " 'KING_NW_KINGNW': [-102.24149, 31.208996],\n",
      " 'KING_SE_KINGSE': [-102.24149, 31.208996],\n",
      " 'KING_SW_KINGSW': [-102.24149, 31.208996],\n",
      " 'LGD_LANGFORD': [-100.610184, 31.095183],\n",
      " 'LGW_UNIT1': [-98.686627, 31.847096],\n",
      " 'LGW_UNIT2': [-98.686627, 31.847096],\n",
      " 'LHORN_N_UNIT1': [-101.307401, 34.345076],\n",
      " 'LHORN_N_UNIT2': [-101.307401, 34.345076],\n",
      " 'LNCRK2_G871': [-99.542699, 32.530972],\n",
      " 'LNCRK2_G872': [-99.542699, 32.530972],\n",
      " 'LNCRK_G83': [-99.542699, 32.530972],\n",
      " 'LONEWOLF_G1': [-100.70936, 32.506124],\n",
      " 'LONEWOLF_G2': [-100.70936, 32.506124],\n",
      " 'LONEWOLF_G3': [-100.70936, 32.506124],\n",
      " 'LONEWOLF_G4': [-100.70936, 32.506124],\n",
      " 'LV3_UNIT_1': [-98.612325, 26.472989],\n",
      " 'LV4_UNIT_1': [-98.517847, 26.499807],\n",
      " 'LV5_UNIT_1': [-98.517847, 26.499807],\n",
      " 'MARIAH_NORTE1': [-102.670416, 34.677698],\n",
      " 'MARIAH_NORTE2': [-102.670416, 34.677698],\n",
      " 'MCDLD_FCW1': [-101.280114, 32.024824],\n",
      " 'MCDLD_SBW1': [-101.280114, 32.024824],\n",
      " 'MESQCRK_WND1': [-101.683502, 32.669103],\n",
      " 'MESQCRK_WND2': [-101.683502, 32.669103],\n",
      " 'MIAM1_G1': [-100.633457, 35.654473],\n",
      " 'MIAM1_G2': [-100.633457, 35.654473],\n",
      " 'MIRASOLE_MIR11': [-98.396504, 26.473188],\n",
      " 'MIRASOLE_MIR12': [-98.396504, 26.473188],\n",
      " 'MIRASOLE_MIR21': [-98.396504, 26.473188],\n",
      " 'MOZART_WIND_1': [-100.531169, 32.994719],\n",
      " 'MWEC_G1': [-100.972712, 33.751761],\n",
      " 'NBOHR_UNIT1': [-101.530192, 31.766443],\n",
      " 'NWF_NWF1': [-102.796692, 32.044332],\n",
      " 'NWF_NWF2': [-102.796692, 32.044332],\n",
      " 'OWF_OWF': [-101.37874, 32.106742],\n",
      " 'PC_NORTH_PANTHER1': [-101.469954, 32.137619],\n",
      " 'PC_SOUTH_PANTHER2': [-101.469954, 32.137619],\n",
      " 'PC_SOUTH_PANTHER3': [-101.469954, 32.137619],\n",
      " 'PH1_UNIT1': [-101.15381, 35.40226],\n",
      " 'PH1_UNIT2': [-101.15381, 35.40226],\n",
      " 'PH2_UNIT1': [-101.15381, 35.40226],\n",
      " 'PH2_UNIT2': [-101.15381, 35.40226],\n",
      " 'PYR_PYRON1': [-100.728414, 32.53232],\n",
      " 'PYR_PYRON2': [-100.728414, 32.53232],\n",
      " 'RDCANYON_RDCNY1': [-101.22708, 32.911705],\n",
      " 'ROUTE_66_WIND1': [-101.527459, 35.214192],\n",
      " 'RSNAKE_G1': [-101.406179, 31.689029],\n",
      " 'RSNAKE_G2': [-101.406179, 31.689029],\n",
      " 'SALTFORK_UNIT1': [-100.888395, 34.987137],\n",
      " 'SALTFORK_UNIT2': [-100.888395, 34.987137],\n",
      " 'SALVTION_UNIT1': [-99.666696, 33.319707],\n",
      " 'SALVTION_UNIT2': [-99.666696, 33.319707],\n",
      " 'SENATEWD_UNIT1': [-98.37243, 33.20315],\n",
      " 'SGMTN_SIGNALM2': [-101.360276, 32.240606],\n",
      " 'SGMTN_SIGNALMT': [-101.360276, 32.240606],\n",
      " 'SHANNONW_UNIT_1': [-98.360133, 33.536155],\n",
      " 'SPLAIN1_WIND1': [-101.371181, 34.147577],\n",
      " 'SPLAIN1_WIND2': [-101.371181, 34.147577],\n",
      " 'SPLAIN2_WIND21': [-101.370029, 34.083655],\n",
      " 'SPLAIN2_WIND22': [-101.370029, 34.083655],\n",
      " 'SRWE1_SRWE2': [-101.592308, 32.946879],\n",
      " 'SRWE1_UNIT1': [-101.592308, 32.946879],\n",
      " 'SSPURTWO_SS3WIND1': [-102.1834, 35.22615],\n",
      " 'SSPURTWO_SS3WIND2': [-102.1834, 35.22615],\n",
      " 'SSPURTWO_WIND_1': [-102.1834, 35.22615],\n",
      " 'STWF_T1': [-100.211385, 32.415988],\n",
      " 'SWEC_G1': [-101.838132, 32.239915],\n",
      " 'SWEETWN2_WND2': [-100.35102, 32.340995],\n",
      " 'SWEETWN2_WND24': [-100.35102, 32.340995],\n",
      " 'SWEETWN3_WND3A': [-100.35102, 32.340995],\n",
      " 'SWEETWN3_WND3B': [-100.35102, 32.340995],\n",
      " 'SWEETWN4_WND4A': [-100.499177, 32.303601],\n",
      " 'SWEETWN4_WND4B': [-100.499177, 32.303601],\n",
      " 'SWEETWN4_WND5': [-100.499177, 32.303601],\n",
      " 'SWEETWND_WND1': [-100.322188, 32.456486],\n",
      " 'SW_MESA_SW_MESA': [-102.120196, 31.084274],\n",
      " 'TKWSW1_ROSCOE': [-100.67276, 32.494611],\n",
      " 'TKWSW1_ROSCOE2A': [-100.67276, 32.494611],\n",
      " 'TRENT_TRENT': [-100.220527, 32.439597],\n",
      " 'TRINITY_TH1_BUS1': [-98.752121, 33.395958],\n",
      " 'TRINITY_TH1_BUS2': [-98.752121, 33.395958],\n",
      " 'TTWEC_G1': [-100.256468, 32.213737],\n",
      " 'TYLRWIND_UNIT1': [-97.386761, 33.722847],\n",
      " 'VERTIGO_WIND_I': [-99.386387, 33.63333],\n",
      " 'WEC_WECG1': [-101.132693, 33.95036],\n",
      " 'WHTTAIL_WR1': [-97.427082, 33.719111],\n",
      " 'WNDTHST2_UNIT1': [-98.522287, 33.540457],\n",
      " 'WOODWRD1_WOODWRD1': [-102.237844, 31.237908],\n",
      " 'WOODWRD2_WOODWRD2': [-102.237844, 31.237908]}\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Downsampling\n",
    "# Motivation: the NAM data exists as a 140*140*9 matrix for every single timestamp.\n",
    "# This covers the entire 140 by 140 grid, with 9 variables per grid square\n",
    "# While very useful data in theory, it requires a significant amount of processing power\n",
    "# Here, we will \"downsample\" this data by extracting its most useful components\n",
    "\n",
    "# One method of doing this is by taking the grid squares closest to the wind farm we want to train on.\n",
    "# Wind farm locations are found using the data_name_to_coords file\n",
    "\n",
    "# Get the ERCOT locations\n",
    "data_name_to_coords = None\n",
    "with open('data_name_to_coords.pkl', 'rb') as handle:\n",
    "    data_name_to_coords = pickle.load(handle)\n",
    "pprint(data_name_to_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a map from grid square coordinates to grid square number\n",
    "# coord_to_square_number = { tuple(location):i for i,location in enumerate(np.reshape(nam_locations, (19600,2)))}\n",
    "# pprint(coord_to_square_number)\n",
    "\n",
    "numbers = range(19600)\n",
    "\n",
    "# Prepare a nearest neighbor interpolator\n",
    "from scipy.interpolate import NearestNDInterpolator\n",
    "myInterpolator = NearestNDInterpolator(np.reshape(nam_locations, (19600,2)), numbers)\n",
    "\n",
    "# Given a specific wind farm, return NAM data within the radius specified\n",
    "def only_proximal_nam_data(original_data_frame, wind_farm_name, radius):\n",
    "    # Find the center of the new subset of NAM data that we want\n",
    "    farm_location = data_name_to_coords[wind_farm_name]\n",
    "    print(farm_location)\n",
    "    central_grid_square = myInterpolator(farm_location[0],farm_location[1])\n",
    "    print(central_grid_square)\n",
    "    central_grid_square = (central_grid_square % 140, central_grid_square // 140)\n",
    "    print(central_grid_square)\n",
    "    lower_bound_x = max(0,central_grid_square[0] - radius)\n",
    "    upper_bound_x = min(140,central_grid_square[0] + radius) # Used in range which is non inclusive\n",
    "    lower_bound_y = max(0,central_grid_square[1] - radius)\n",
    "    upper_bound_y = min(139,central_grid_square[1] + radius) # Used in range which is non inclusive\n",
    "    print(lower_bound_x)\n",
    "    print(upper_bound_x)\n",
    "    print(lower_bound_y)\n",
    "    print(upper_bound_y)\n",
    "\n",
    "#     central_grid_square = find_central_grid_square(data_name_to_coords[wind_farm_name])\n",
    "    \n",
    "    # Now a question is, how are we obtaining a subset of the NAM data?\n",
    "    # Is this going to be vectorized or a loop?\n",
    "    # Is this going to be with all NAM data simultaneously? Or done piecewise to avoid OOM?\n",
    "#     proximal_nam_data = np.array()\n",
    "    localized_training_df = original_data_frame['data_objects'].map(lambda full_data: full_data[range(lower_bound_x, upper_bound_x),range(lower_bound_y, upper_bound_y)])\n",
    "    return localized_training_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-98.843784, 27.608743]\n",
      "4696\n",
      "(76, 33)\n",
      "74\n",
      "78\n",
      "31\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "# Testing out the function to only return proximal NAM data, seems to be working\n",
    "# puny_nam_training = nam_training_df.iloc[:10,:]\n",
    "# # pprint(puny_nam_training)\n",
    "\n",
    "# test_run_nam_training = only_proximal_nam_data(puny_nam_training,  'CEDROHIL_CHW2', 2)\n",
    "# pprint(test_run_nam_training)\n",
    "# pprint(test_run_nam_training.iloc[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten each 140*140*9 array, and stack those to create a matrix of data points\n",
    "# Then train on that + the vector of ERCOT data values for a single farm\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Can't call method in apply, so instead have a wrapper function to call the method\n",
    "def flatten_wrapper(np_array):\n",
    "    return np_array.flatten()\n",
    "\n",
    "def reshape_regression_data(df):\n",
    "    regression_data = df.apply(flatten_wrapper).values\n",
    "    regression_tuple = tuple(regression_data)\n",
    "    del regression_data\n",
    "    gc.collect()\n",
    "    nam_matrix = np.stack(regression_tuple, axis = 0)\n",
    "    del regression_tuple\n",
    "    gc.collect()\n",
    "    return nam_matrix\n",
    "\n",
    "def reshape_other_data(other_data):\n",
    "    other_data = other_data.values.reshape(other_data.shape[0], 1)\n",
    "    return other_data\n",
    "\n",
    "def run_linear_regression(data1, data2):\n",
    "    lm = linear_model.LinearRegression()\n",
    "    model = lm.fit(data1, data2)   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100.15802, 29.215214]\n",
      "6785\n",
      "(65, 48)\n",
      "62\n",
      "68\n",
      "45\n",
      "51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Localize and Reshape the training dataframe\n",
    "reshaped_nam_training = reshape_regression_data(only_proximal_nam_data(nam_training_df, 'ANACACHO_ANA', 3))\n",
    "# Delete the original Pandas dataframe from memory\n",
    "del nam_training_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape the other training dataframe\n",
    "reshaped_ercot_training_0 =  reshape_other_data(ercot_training_df.iloc[:,0])\n",
    "# Delete the original Pandas dataframe from memory\n",
    "del ercot_training_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nam_training_model = run_linear_regression(reshaped_nam_training, reshaped_ercot_training_0)\n",
    "del reshaped_nam_training\n",
    "del reshaped_ercot_training_0\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.01937786e-01 -8.72202337e-01  1.91381783e-03  1.49262398e-01\n",
      "   4.47013676e-02  1.04719889e+00 -3.09559051e-03 -7.04252064e-01\n",
      "  -2.31820047e-01  7.60008931e-01  6.63485527e-01 -1.87379122e-03\n",
      "  -7.57489428e-02 -4.33148667e-02 -1.14215565e+00  1.90939754e-03\n",
      "   2.20099792e-01  2.08827555e-01 -1.36821294e+00  2.62580931e-01\n",
      "   7.72520900e-04 -7.05151930e-02 -2.21049003e-02 -1.17932212e+00\n",
      "  -1.95845612e-03  4.03062791e-01 -7.69560784e-02  4.83372033e-01\n",
      "  -1.48556128e-01 -2.66874582e-03 -1.68638900e-02  5.93578964e-02\n",
      "   1.65483546e+00 -5.93669713e-04  8.27404737e-01  1.82676244e+00\n",
      "   6.82609856e-01 -1.35125652e-01 -2.81143188e-03  5.71908951e-02\n",
      "  -4.88084555e-02  3.27686548e-01  1.36613846e-03 -1.40101707e+00\n",
      "  -2.91446090e+00  1.82623714e-01  1.78244829e-01  3.87400389e-04\n",
      "  -6.69064522e-02  6.88600540e-03 -9.33087349e-01 -8.08507204e-04\n",
      "   3.20182234e-01  1.51046586e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(nam_training_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the NAM testing information\n",
    "nam_testing_df = None\n",
    "for i in range(32):\n",
    "    testing_part = pd.read_pickle(cleaned_data + testing_data_filename + str(i) + extension, compression='gzip')\n",
    "    nam_testing_df = testing_part if nam_testing_df is None else nam_testing_df.append(testing_part)\n",
    "del testing_part\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                data_objects\n",
      "timestamps                                                                  \n",
      "2015-01-01 00:00:00-06:00  [[[0.0, 290.7572, 0.0, 75.0, 101402.0, 295.582...\n",
      "2015-01-02 01:00:00-06:00  [[[0.0, 290.68527, 0.0, 77.0, 101398.0, 294.99...\n",
      "2015-01-03 02:00:00-06:00  [[[0.0, 285.07336, 0.0, 59.0, 101692.0, 293.30...\n",
      "2015-01-04 03:00:00-06:00  [[[0.0, 287.89383, 0.0, 68.0, 101669.0, 294.14...\n",
      "2015-01-05 04:00:00-06:00  [[[0.0, 288.7345, 0.0, 66.0, 101515.0, 295.621...\n",
      "                                                                data_objects\n",
      "timestamps                                                                  \n",
      "2018-12-27 06:00:00-06:00  [[[0.0, 286.81763, 0.0, 68.75848, 101341.82, 2...\n",
      "2018-12-28 07:00:00-06:00  [[[0.0, 285.78033, 0.0, 59.046467, 101340.87, ...\n",
      "2018-12-29 08:00:00-06:00  [[[0.0, 289.72476, 5.5, 79.63069, 101430.37, 2...\n",
      "2018-12-30 09:00:00-06:00  [[[0.0, 283.95175, 161.0, 60.42068, 101588.39,...\n",
      "2018-12-31 10:00:00-06:00  [[[0.0, 283.46255, 411.0, 61.39987, 101684.586...\n"
     ]
    }
   ],
   "source": [
    "pprint(nam_testing_df[:5])\n",
    "pprint(nam_testing_df[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ERCOT testing information\n",
    "ercot_testing_df = pd.read_pickle(cleaned_data + testing_expected_output_filename + extension, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resource_code              ANACACHO_ANA  ASTRA_UNIT1  BCATWIND_WIND_1\n",
      "timestamp                                                            \n",
      "2015-01-01 00:00:00-06:00      0.000000          NaN         0.000000\n",
      "2015-01-02 01:00:00-06:00      0.825478          NaN         0.000000\n",
      "2015-01-03 02:00:00-06:00      5.294131          NaN         0.967167\n",
      "2015-01-04 03:00:00-06:00     23.222590          NaN        35.644380\n",
      "2015-01-05 04:00:00-06:00      6.198874          NaN         2.759169\n",
      "resource_code              ANACACHO_ANA  ASTRA_UNIT1  BCATWIND_WIND_1\n",
      "timestamp                                                            \n",
      "2018-12-27 06:00:00-06:00     18.213490     40.30907        25.250760\n",
      "2018-12-28 07:00:00-06:00      6.029018     30.74844         4.998176\n",
      "2018-12-29 08:00:00-06:00      5.078777      0.00000         3.735878\n",
      "2018-12-30 09:00:00-06:00      1.002264     31.68289         0.000000\n",
      "2018-12-31 10:00:00-06:00      0.000000     39.24713        29.878060\n"
     ]
    }
   ],
   "source": [
    "pprint(ercot_testing_df.iloc[:5,:3])\n",
    "pprint(ercot_testing_df.iloc[-5:,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100.15802, 29.215214]\n",
      "6785\n",
      "(65, 48)\n",
      "62\n",
      "68\n",
      "45\n",
      "51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape the training dataframe\n",
    "reshaped_nam_testing = reshape_regression_data(only_proximal_nam_data(nam_testing_df, 'ANACACHO_ANA', 3))\n",
    "# Delete the original Pandas dataframe from memory\n",
    "del nam_testing_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape the training dataframe\n",
    "reshaped_ercot_testing_0 = reshape_other_data(ercot_testing_df.iloc[:,0])\n",
    "# Delete the original Pandas dataframe from memory\n",
    "del ercot_testing_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25510180462531085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(nam_training_model.score(reshaped_nam_testing, reshaped_ercot_testing_0))\n",
    "del reshaped_nam_testing\n",
    "del reshaped_ercot_testing_0\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the linear regression model to a file\n",
    "filename = 'nam_basic_regression_model.sav'\n",
    "pickle.dump(nam_training_model, open(filename, 'wb'))\n",
    "# to later load the model from disk, run:\n",
    "# loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
