{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the NAM data (split into training and testing)\n",
    "# NOTE: must have run the \"nam_data_preparation.ipynb\" notebook beforehand\n",
    "\n",
    "# Read the training and testing data from disk\n",
    "cleaned_data = \"cleaned_data/\"\n",
    "training_data_filename = \"nam_training_\"\n",
    "testing_data_filename = \"nam_testing_\"\n",
    "extension = \".pkl.gz\"\n",
    "nam_training_df = None\n",
    "for i in range(32):\n",
    "    training_part = pd.read_pickle(cleaned_data + training_data_filename + str(i) + extension, compression='gzip')\n",
    "    nam_training_df = training_part if nam_training_df is None else nam_training_df.append(training_part)\n",
    "    del training_part\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                data_objects\n",
      "timestamps                                                                  \n",
      "2015-01-01 01:00:00-06:00  [[[0.0, 290.43628, 0.0, 73.0, 101516.0, 295.77...\n",
      "2015-01-01 02:00:00-06:00  [[[0.0, 290.8083, 0.0, 74.0, 101502.0, 295.740...\n",
      "2015-01-01 03:00:00-06:00  [[[0.0, 290.99026, 0.0, 75.0, 101467.0, 295.66...\n",
      "2015-01-01 04:00:00-06:00  [[[0.0, 290.83884, 0.0, 75.0, 101436.0, 295.67...\n",
      "2015-01-01 05:00:00-06:00  [[[0.0, 290.83582, 0.0, 75.0, 101412.0, 295.64...\n",
      "                                                                data_objects\n",
      "timestamps                                                                  \n",
      "2018-12-31 17:00:00-06:00  [[[0.0, 283.83853, 268.59998, 58.5307, 101409....\n",
      "2018-12-31 18:00:00-06:00  [[[0.0, 284.02292, 77.4, 58.640553, 101367.984...\n",
      "2018-12-31 19:00:00-06:00  [[[0.0, 284.31033, 51.6, 59.009323, 101398.63,...\n",
      "2018-12-31 20:00:00-06:00  [[[0.0, 284.59775, 25.8, 59.378094, 101429.28,...\n",
      "2018-12-31 21:00:00-06:00  [[[0.0, 284.88516, 0.0, 59.746864, 101459.94, ...\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Print the training dataset out\n",
    "pprint(nam_training_df[:5])\n",
    "pprint(nam_training_df[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the ERCOT data (reduced hourly and split into train/test in a 24:1 ratio)\n",
    "\n",
    "training_expected_output_filename = \"ercot_for_nam_training\"\n",
    "testing_expected_output_filename = \"ercot_for_nam_testing\"\n",
    "\n",
    "# If we haven't already done this split, do it now and save the contents to disk\n",
    "if not path.exists(cleaned_data + training_expected_output_filename + extension) or not path.exists(cleaned_data + testing_expected_output_filename + extension):\n",
    "    print(\"cleaning ERCOT data for NAM purposes\")\n",
    "    # Get generically cleaned ERCOT data, not specifically set up for use with NAM\n",
    "    ercot_wind_power = pd.read_pickle(\"ercot_wind_power.pkl\")\n",
    " \n",
    "    # ERCOT data is every 15 minutes, while the NAM data is hourly\n",
    "    # We therefore only use the ERCOT data on the hour, when working with NAM\n",
    "    hourly_ercot = ercot_wind_power[::4]\n",
    "\n",
    "    # Small change: NAM ends at 21:00 on Dec 31 2018, while ERCOT ends at 23:00\n",
    "    # So cut out the last two entries of hourly_ercot\n",
    "    hourly_ercot = hourly_ercot.iloc[:-2]\n",
    "\n",
    "    # Split the ERCOT data to line up with the NAM data\n",
    "    hourly_ercot['numerical_index'] = range(0, len(hourly_ercot))\n",
    "    ercot_training_df = hourly_ercot[hourly_ercot['numerical_index'] % 25 != 0]\n",
    "    ercot_testing_df = hourly_ercot[hourly_ercot['numerical_index'] % 25 == 0]\n",
    "    del hourly_ercot\n",
    "    gc.collect()\n",
    "    ercot_training_df = ercot_training_df.drop('numerical_index', 1)\n",
    "    ercot_testing_df = ercot_testing_df.drop('numerical_index', 1)\n",
    "    \n",
    "    # Save the ERCOT data to file\n",
    "    ercot_training_df.to_pickle(cleaned_data + training_expected_output_filename + extension, compression='gzip')\n",
    "    ercot_testing_df.to_pickle(cleaned_data + testing_expected_output_filename + extension, compression='gzip')\n",
    "    del ercot_training_df\n",
    "    del ercot_testing_df\n",
    "    gc.collect()\n",
    "\n",
    "# Get the NAM-specific ERCOT data from disk\n",
    "ercot_training_df = pd.read_pickle(cleaned_data + training_expected_output_filename + extension, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resource_code              ANACACHO_ANA  ASTRA_UNIT1  BCATWIND_WIND_1\n",
      "timestamp                                                            \n",
      "2015-01-01 01:00:00-06:00           0.0          NaN              0.0\n",
      "2015-01-01 02:00:00-06:00           0.0          NaN              0.0\n",
      "2015-01-01 03:00:00-06:00           0.0          NaN              0.0\n",
      "2015-01-01 04:00:00-06:00           0.0          NaN              0.0\n",
      "2015-01-01 05:00:00-06:00           0.0          NaN              0.0\n",
      "resource_code              ANACACHO_ANA  ASTRA_UNIT1  BCATWIND_WIND_1\n",
      "timestamp                                                            \n",
      "2018-12-31 17:00:00-06:00      0.000000     33.30522         11.35381\n",
      "2018-12-31 18:00:00-06:00      0.000000     36.93887         12.76649\n",
      "2018-12-31 19:00:00-06:00      0.000000     38.98851         23.02475\n",
      "2018-12-31 20:00:00-06:00      0.582387     39.37746         34.87904\n",
      "2018-12-31 21:00:00-06:00      7.234724     39.16596         33.18754\n"
     ]
    }
   ],
   "source": [
    "# Print the training dataset out\n",
    "pprint(ercot_training_df.iloc[:5,:3])\n",
    "pprint(ercot_training_df.iloc[-5:,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten each 140*140*9 array, and stack those to create a matrix of data points\n",
    "# Then train on that + the vector of ERCOT data values for a single farm\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Can't call method in apply, so instead have a wrapper function to call the method\n",
    "def flatten_wrapper(np_array):\n",
    "    return np_array.flatten()\n",
    "\n",
    "def reshape_regression_data(df):\n",
    "    regression_data = df['data_objects'].apply(flatten_wrapper).values\n",
    "    regression_tuple = tuple(regression_data)\n",
    "    del regression_data\n",
    "    gc.collect()\n",
    "    nam_matrix = np.stack(regression_tuple, axis = 0)\n",
    "    del regression_tuple\n",
    "    gc.collect()\n",
    "    return nam_matrix\n",
    "\n",
    "def reshape_other_data(other_data):\n",
    "    other_data = other_data.values.reshape(other_data.shape[0], 1)\n",
    "    return other_data\n",
    "\n",
    "def run_linear_regression(data1, data2):\n",
    "    lm = linear_model.LinearRegression()\n",
    "    model = lm.fit(data1, data2)   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "yo\n",
      "hey\n",
      "wassup\n"
     ]
    }
   ],
   "source": [
    "# Reshape the training dataframe\n",
    "reshaped_nam_training = reshape_regression_data(nam_training_df)\n",
    "# Delete the original Pandas dataframe from memory\n",
    "del nam_training_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the other training dataframe\n",
    "reshaped_ercot_training_0 =  reshape_other_data(ercot_training_df.iloc[:,0])\n",
    "# Delete the original Pandas dataframe from memory\n",
    "del ercot_training_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nam_training_model = run_linear_regression(reshaped_nam_training, reshaped_ercot_training_0)\n",
    "del reshaped_nam_training\n",
    "del reshaped_ercot_training_0\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nam_training_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the NAM testing information\n",
    "nam_testing_df = None\n",
    "for i in range(32):\n",
    "    testing_part = pd.read_pickle(cleaned_data + testing_data_filename + str(i) + extension, compression='gzip')\n",
    "    nam_testing_df = testing_part if nam_testing_df is None else nam_testing_df.append(testing_part)\n",
    "del testing_part\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(nam_testing_df[:5])\n",
    "pprint(nam_testing_df[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ERCOT testing information\n",
    "ercot_testing_df = pd.read_pickle(cleaned_data + testing_expected_output_filename + extension, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(ercot_testing_df.iloc[:5,:3])\n",
    "pprint(ercot_testing_df.iloc[-5:,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the training dataframe\n",
    "reshaped_nam_testing = reshape_regression_data(nam_testing_df)\n",
    "# Delete the original Pandas dataframe from memory\n",
    "del nam_testing_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the training dataframe\n",
    "reshaped_ercot_testing_0 = reshape_other_data(ercot_testing_df.iloc[:,0])\n",
    "# Delete the original Pandas dataframe from memory\n",
    "del ercot_testing_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nam_training_model.score(reshaped_nam_testing, reshaped_ercot_testing_0))\n",
    "del reshaped_nam_testing\n",
    "del reshaped_ercot_testing_0\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nam_training_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1f896d006203>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Save the linear regression model to a file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'nam_basic_regression_model.sav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnam_training_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'nam_training_model' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# Save the linear regression model to a file\n",
    "filename = 'nam_basic_regression_model.sav'\n",
    "pickle.dump(nam_training_model, open(filename, 'wb'))\n",
    "# to later load the model from disk, run:\n",
    "# loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
